# -*- coding: utf-8 -*-
"""Balaji Restaurant sales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H21cTLuarWs2RWP8xUX_-D_3M2QR_klE
"""

# importing the libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#  importing the dataset
dataset = pd.read_csv('Balaji Fast Food Sales.csv')
dataset

# Checking the first 3 datas
dataset.head(3)

# Checking the last 3 datas
dataset.tail(3)

# Checking if there are any duplications or not
print(dataset.duplicated().sum())
# No duplications were found

# Checking the null values
dataset.isnull().sum()
# Null values were present in transaction type column

# Solving the null values problem in transaction type column
dataset['transaction_type'] = dataset['transaction_type'].fillna('Unknown')

dataset.isnull().sum()
# Null values in transaction type were replaced by Unknown

# Basic Information of datas

dataset.columns

dataset.describe()

dataset.shape
# 1000 rows and 10 columns

dataset.info()

# Since the date column in the dataset are object and separated by '-' and '/'. Hence we first replace the separation into one
dataset['date'] = dataset['date'].str.replace('-','/')

dataset['date']

# Converting date to datetime and separating them
dataset['Date'] = pd.to_datetime(dataset['date'], dayfirst= False)
dataset['Month'] = dataset['Date'].dt.month_name()
dataset['Day'] = dataset['Date'].dt.day_name()
dataset['Year'] = dataset['Date'].dt.year

# Dropping the date  column since it has been separated and converted to datetime
dataset.drop('date',axis = 1, inplace = True)

dataset

# Replacing the Mr and Mrs in received_by column to male and female
dataset['received_by'] = dataset['received_by'].replace(['Mr.'],['Male'])
dataset['received_by'] = dataset['received_by'].replace(['Mrs.'],['Female'])

# Checking the unique values in each row

print(dataset['item_name'].unique())

print(dataset['item_type'].unique())

print(dataset['item_price'].unique())

print(dataset['transaction_type'].unique())

print(dataset['received_by'].unique())

print(dataset['time_of_sale'].unique())

print(dataset['Year'].unique())

months_2022 = dataset[dataset['Year']== 2022]['Month'].unique()
print(f'The months in 2022 are:{months_2022}')

months_2023 = dataset[dataset['Year']== 2023]['Month'].unique()
print(f'The months in 2023 are:{months_2023}')

# Looking further information on objects

dataset.describe(include = object)

# Solving some questions for insights

# 1) What is the total revenue in both years ?
revenue_2022 = dataset[dataset['Year']== 2022]['transaction_amount'].sum()
print(f'The total revenue in year 2022 is: {revenue_2022}')

revenue_2023 = dataset[dataset['Year']== 2023]['transaction_amount'].sum()
print(f'The total revenue in 2023 is: {revenue_2023}')

# 2) Which item generates the highest revenue?
highest_revenue_items = dataset.groupby('item_name')['transaction_amount'].sum().sort_values(ascending = False)
print(highest_revenue_items)
# Sandwich generates the highest revenue followed by Frankie and Cold Coffee

# 3) What time of sale generates the highest revenue?
Time_of_sale_revenue = dataset.groupby('time_of_sale')['transaction_amount'].sum().sort_values(ascending = False)
print(Time_of_sale_revenue)
# Highest revenue is generated at Night followed by Afternoon and Morning.

# 4) Most expensive and least expensive items?
Most_expensive = dataset.groupby('item_name')['item_price'].max().sort_values(ascending = False)
print(Most_expensive)
# Sandwich is the most expensive followed by Frankie and Cold Coffee.
# Vadapav is least expensive followed by panipuri and aalopuri.

# 5) Most Sold items
Most_sold = dataset.groupby('item_name')['quantity'].sum().sort_values(ascending = False)
print(Most_sold)
# Cold Coffee is the most sold followed by Sugarcane Juice and Panipuri

# 6) Preferred transactions.
Most_preferred_transactions = dataset['transaction_type'].value_counts().sort_values(ascending = False)
print(Most_preferred_transactions)
# Cash is the most preferred transaction

# 7) Which gender handles the most transactions ?
gender_order = dataset['received_by'].value_counts()
print(gender_order)
# Male handles the most transactions when compared to Female

# 8) Which gender handles the transaction order for the most food type?
order_per_gender = dataset.groupby('received_by')['item_name'].value_counts()
print(order_per_gender)
# Female and Male mostly handle the transaction of Cold Coffee.

# Visualization through matplotlib

# Most and least expensive products
plt.figure(figsize = (10,5))
price_products = plt.bar(Most_expensive.index, Most_expensive.values, color = 'gold')
plt.title('Products and Price')
plt.xlabel('Products')
plt.ylabel('Price')
plt.show()

# Most sold Products
plt.figure(figsize = (10,5))
most_sold = plt.bar(Most_sold.index,Most_sold.values, color = 'peru')
plt.title('Most Sold products By Quantities')
plt.xlabel('Products')
plt.ylabel('Quantities')
plt.show()

# Revenue Generator
plt.figure(figsize = (10,5))
revenue_generator = plt.barh(highest_revenue_items.index, highest_revenue_items.values, color = 'olive')
plt.title('Highest Revenue by Products')
plt.xlabel('Products')
plt.ylabel('Revenue')
plt.show()

# Transaction Handling
plt.figure(figsize = (8,8))
customers = plt.pie(gender_order.values,labels = gender_order.index, autopct = '%1.1f%%',startangle= 90, colors = ['darkorange','olive'])
plt.title('Transaction Handling')
plt.show()

# Boxplot to find out outliers

plt.boxplot(dataset['item_price'])
plt.show()
# No Outliers

plt.boxplot(dataset['transaction_amount'])
plt.show()
# There are outliers

# Finding the outliers
q1 = dataset['transaction_amount'].quantile(0.25)
print(f'q1 is: {q1}')
q3 = dataset['transaction_amount'].quantile(0.75)
print(f'q3 is: {q3}')
IQR = q3 - q1
print(f'The IQR is: {IQR}')
lower_bound = q1 - 1.5 * IQR
print(f'The lower bound is: {lower_bound}')
upper_bound = q3 + 1.5 * IQR
print(f' The upper bound is: {upper_bound}')
outliers = dataset[(dataset['transaction_amount']< lower_bound) | (dataset['transaction_amount'] > upper_bound)]
print(f'The outliers are: {outliers}')
print(len(outliers))

# Use of Seaborn

# Correlation between price and quantity
correlation_1 = dataset[['item_price','quantity']].corr()
print(correlation_1)
# There is a little positive correlation between price and quantity.
# This indicates that increase in price of products leads to small increment in quantity.

# Correlation between price and transaction_amount
correlation_2 = dataset[['item_price','transaction_amount']].corr()
print(correlation_2)
# There is a strong positive relationship between price and transaction amount.
# This indicates that increase in price of products leads to increase in transaction amount.

# Correlation between quantity and transaction amount
correlation_3 = dataset[['quantity','transaction_amount']].corr()
print(correlation_3)
# There is a strong positive relationship between quantity and transaction amount.
# This results that ncrease in quantity leads to increment in transaction amount.

pairplot = sns.pairplot(dataset[['item_price','quantity','transaction_amount']])
print(pairplot)

# Merged correlation
merged_correlation = dataset[['item_price','quantity','transaction_amount']].corr()
print(merged_correlation)

# Heatmap
sns.heatmap(merged_correlation, vmin = -1, vmax = 1, annot = True)

"""SUMMARY OF THE DATASET

1. Sandwich is the most expensive item (Rs 60) followed by Frankie (Rs 50) and Cold Coffee (Rs 40).

2. At Night most revenue is generated (Rs 62075) followed by Afternoon (Rs 56345) and Morning (Rs 53730).

3. Sandwich generates the highest revenue (Rs 65820) followed by Frankie (Rs 57500) and Cold Coffee (Rs 54440).

4. Cold Coffee is most sold item (1361 times) followed by Sugarcane Juice (1278 times) and Panipuri (1226 times).

5. Most Preferred transaction is Cash (476 times) followed by Online (417 times) and Unknown (107 times).

6. Male handles the transaction the most (512 times) followed by Female(488 times).

7. Male mostly handles the transaction related to the order of Cold Coffee (79 times) followed by Frankie (76 times) and Sugarcane Juice (74 times).

8. Female mostly handles the transaction reated to the order of Cold Coffee (82) followed by Sugarcane Juice (79 times) and Panipuri (77 times).

9. There is a little positive correlation between price and quantity.
This indicates that increase in price of products leads to small increment in quantity.

10. There is a strong positive relationship between price and transaction amount.This indicates that increase in price of products leads to increase in transaction amount.

11. There is a strong positive relationship between quantity and transaction amount. This results that ncrease in quantity leads to increment in transaction amount.

12. Outliers were found through boxplot in transaction amount. It can be due to bulk orders for various products.

RECOMMENDATIONS

1. Although Sandwich were the most expensive items but Cold Coffee, Sugarcane juice, Frankie were sold most in quantites and are also one of the top revenue generators having low price than sandwich . This shows that Cold Coffee and Sugarcane juice has the prices which are favourable to all type of consumers. Hence, experimentation can be done on Sandwiches by decreasing the cost for a while and advertising more on their sandwich products.

2. Male and Female both mostly handle the transaction related to Cold Coffee, Sugarcane, and Frankie. Hence, the restaurant should maintain the quality of these prodcuts.

3. Although the price of panipuri is less (20) but it is one of the most sold items in terms of quantites but generates low revenue due to its low price. Therefore, the restaurant can experiment by slightly increasing the price of panipuri and review the performance in terms of quantities sold and revenue generated.

4. Aalopuri and vadapav are least sold in terms of quantites. Hence, the restaurant needs to advertise these products more or they can provide a combo meal which includes these items with others to sell more of these products.

LIMITATIONS

1. This dataset contains the data of only 2 year (2022) and (2023) where the months in both the years are also incomplete. Hence, the long term trend analysis is not possible due to incomplete months.
"""

dataset.to_csv('Balaji Restaurant cleaned.csv')























































































































